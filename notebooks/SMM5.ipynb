{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6Zae/E+Z+R9SUbPkt20Qy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitbhutani1090/value_of_data/blob/main/notebooks/SMM5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hLuQFViNmEte"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "import seaborn as sns\n",
        "from scipy.special import erfinv  # for lognormal quantile grid\n",
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "project_dir = '/content/drive/MyDrive/Data_GDP_OV'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "_UCyZKAQqR1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diagnostics Functions"
      ],
      "metadata": {
        "id": "qIYWglHqpMiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class DiagLite:\n",
        "    # --- VFI (solve) ---\n",
        "    flow_floor_hits: int = 0          # # times A - γ·ω (or (1-γ·ω)A) was floored at PROD_FLOOR\n",
        "    flow_total_vfi: int = 0           # total # flow checks (≈ Nw per VFI iteration per a-node)\n",
        "    den_floor_hits_vfi: int = 0       # # times omega denominator floored at DEN_FLOOR\n",
        "    den_total_vfi: int = 0            # total # denominator evaluations in VFI (≈ Nw*Nk per iter per a-node)\n",
        "    k_at_min_states: int = 0          # # states where policy picked k_min\n",
        "    k_at_max_states: int = 0          # # states where policy picked k_max\n",
        "    states_count: int = 0             # total # states considered for policy edges (≈ Nw per VFI iteration per a-node)\n",
        "    nans_vfi: int = 0                 # # NaN/Inf incidents in VFI\n",
        "\n",
        "    # --- Simulation ---\n",
        "    real_floor_hits: int = 0          # # times A - γ·ψ² (or (1-γ·ψ²)A) was floored at PROD_FLOOR\n",
        "    real_total_sim: int = 0           # total firm-years\n",
        "    den_floor_hits_sim: int = 0       # # times omega denominator floored at DEN_FLOOR\n",
        "    den_total_sim: int = 0            # total # denom evaluations in SIM (== firm-years)\n",
        "    omega_at_min_sim: int = 0         # # times ω' hit lower grid bound\n",
        "    omega_at_max_sim: int = 0         # # times ω' hit upper grid bound\n",
        "    omega_updates_sim: int = 0        # total # ω updates (== firm-years)\n",
        "    nans_sim: int = 0                 # # NaN/Inf incidents in SIM\n",
        "\n",
        "    def report(self, label=\"\"):\n",
        "        msgs = []\n",
        "\n",
        "        # VFI percentages\n",
        "        if self.flow_total_vfi > 0 and self.flow_floor_hits > 0:\n",
        "            pct = 100.0 * self.flow_floor_hits / self.flow_total_vfi\n",
        "            msgs.append(f\"[{label}] flow productivity floored: {pct:.2f}% \"\n",
        "                        f\"({self.flow_floor_hits}/{self.flow_total_vfi})\")\n",
        "        if self.den_total_vfi > 0 and self.den_floor_hits_vfi > 0:\n",
        "            pct = 100.0 * self.den_floor_hits_vfi / self.den_total_vfi\n",
        "            msgs.append(f\"[{label}] omega-denominator floored (VFI): {pct:.2f}% \"\n",
        "                        f\"({self.den_floor_hits_vfi}/{self.den_total_vfi})\")\n",
        "        if self.states_count > 0:\n",
        "            pct_min = 100.0 * self.k_at_min_states / self.states_count\n",
        "            pct_max = 100.0 * self.k_at_max_states / self.states_count\n",
        "            msgs.append(f\"[{label}] policy grid hits: k_min={pct_min:.2f}%, \"\n",
        "                        f\"k_max={pct_max:.2f}% (of {self.states_count} states)\")\n",
        "        if self.nans_vfi:\n",
        "            msgs.append(f\"[{label}] NaNs/Infs in VFI: {self.nans_vfi}\")\n",
        "\n",
        "        # SIM percentages\n",
        "        if self.real_total_sim > 0 and self.real_floor_hits > 0:\n",
        "            pct = 100.0 * self.real_floor_hits / self.real_total_sim\n",
        "            msgs.append(f\"[{label}] realized productivity floored: {pct:.2f}% \"\n",
        "                        f\"({self.real_floor_hits}/{self.real_total_sim})\")\n",
        "        if self.den_total_sim > 0 and self.den_floor_hits_sim > 0:\n",
        "            pct = 100.0 * self.den_floor_hits_sim / self.den_total_sim\n",
        "            msgs.append(f\"[{label}] omega-denominator floored (SIM): {pct:.2f}% \"\n",
        "                        f\"({self.den_floor_hits_sim}/{self.den_total_sim})\")\n",
        "        if self.omega_updates_sim > 0 and (self.omega_at_min_sim or self.omega_at_max_sim):\n",
        "            pct_min = 100.0 * self.omega_at_min_sim / self.omega_updates_sim\n",
        "            pct_max = 100.0 * self.omega_at_max_sim / self.omega_updates_sim\n",
        "            msgs.append(f\"[{label}] omega bound hits (SIM): min={pct_min:.2f}%, \"\n",
        "                        f\"max={pct_max:.2f}% (of {self.omega_updates_sim} updates)\")\n",
        "        if self.nans_sim:\n",
        "            msgs.append(f\"[{label}] NaNs/Infs in SIM: {self.nans_sim}\")\n",
        "\n",
        "        if msgs:\n",
        "            print(\"\\n\".join(msgs))"
      ],
      "metadata": {
        "id": "1pd5M_3vpSC2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Other utilities"
      ],
      "metadata": {
        "id": "9uDu4KW4pYvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# Utilities\n",
        "# ==========================\n",
        "def lognormal_grid(mu_lnA, sd_lnA, N):\n",
        "    \"\"\"\n",
        "    Quantile grid for A from LogNormal(mu, sd) using inverse-CDF of Normal.\n",
        "    \"\"\"\n",
        "    qs = np.linspace(0.01, 0.99, N)\n",
        "    lnA = mu_lnA + sd_lnA * np.sqrt(2.0) * erfinv(2 * qs - 1)\n",
        "    return np.exp(lnA)\n",
        "\n",
        "def softfloor(x, floor, k=50.0):\n",
        "    \"\"\"\n",
        "    Smooth approximation of max(x, floor) using numerically stable softplus.\n",
        "    \"\"\"\n",
        "    z = k * (x - floor)\n",
        "    softplus = np.empty_like(z)\n",
        "\n",
        "    pos = z > 0\n",
        "    # For z > 0: softplus(z) = z + log1p(exp(-z)) (exp(-z) is tiny, safe)\n",
        "    softplus[pos] = z[pos] + np.log1p(np.exp(-z[pos]))\n",
        "    # For z <= 0: softplus(z) = log1p(exp(z)) (exp(z) <= 1, safe)\n",
        "    softplus[~pos] = np.log1p(np.exp(z[~pos]))\n",
        "\n",
        "    return floor + softplus / k"
      ],
      "metadata": {
        "id": "Jm8YtNGLpbwt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VFI and Simulation functions"
      ],
      "metadata": {
        "id": "HnUApVoApfS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def productivity_term(a, varTerm, gamma, mode, w):\n",
        "    \"\"\"\n",
        "    mode: additive or multiplicative\n",
        "    Uses soft flooring to avoid non-differentiable kinks.\n",
        "    \"\"\"\n",
        "    if mode == \"additive\":\n",
        "        raw = a - gamma * varTerm - w\n",
        "    elif mode == \"multiplicative\":\n",
        "        raw = a * (1.0 - gamma * varTerm) - w\n",
        "    else:\n",
        "        raise ValueError(\"mode must be additive or multiplicative\")\n",
        "\n",
        "    # soft floor instead of hard max\n",
        "    prod = softfloor(raw, PROD_FLOOR, k=10.0)\n",
        "    return prod\n",
        "\n",
        "def omega_next_from_rev(Rev, phi, tau, chi, Rev_M):\n",
        "    \"\"\"\n",
        "    Implements: omega' = 1 / max(phi + tau + chi * log(max(Rev/Rev_M, eps)), DEN_FLOOR).\n",
        "    Returns (omega_next, den_raw, den_floored)\n",
        "    \"\"\"\n",
        "    ratio = np.maximum(Rev / Rev_M, RATIO_EPS)\n",
        "    den   = phi + tau + chi * np.log(ratio)\n",
        "    den_f = np.maximum(den, DEN_FLOOR)\n",
        "    return 1.0 / den_f, den, den_f\n",
        "\n",
        "\n",
        "# ==========================\n",
        "# Grid builder (robust-ish)\n",
        "# ==========================\n",
        "def make_grids(mu_lnA, sd_lnA,\n",
        "               N_a=9, N_w=60, N_k=80,\n",
        "               alpha=1/3, r=0.04,\n",
        "               phi=142.86, tau=312.04, chi=3.0, Rev_M=692.357,\n",
        "               gamma=2.0, prod_mode=\"additive\", w = 0.01,\n",
        "               k_min=1e-6, logRev_cap=11, a_ref_q=0.99,\n",
        "               omega_min = 1e-7, omega_max = 0.2):\n",
        "    \"\"\"\n",
        "    Builds (a_grid, omega_grid, k_grid).\n",
        "      - a_grid: lognormal quantiles\n",
        "      - k_grid: geometric [k_min, k_max] based on myopic at worst-info omega ≈ 1/phi\n",
        "      - omega_grid: geometric between model-based bounds implied by log link\n",
        "    \"\"\"\n",
        "    a_grid = lognormal_grid(mu_lnA, sd_lnA, N_a)\n",
        "    A_ref = np.quantile(a_grid, a_ref_q)\n",
        "\n",
        "    # k_max from myopic formula at worst-info omega ≈ 1/phi, using selected productivity spec\n",
        "    omega_worst = 1.0 / 2\n",
        "    coeff_flow_worst = productivity_term(A_ref, omega_worst, gamma, prod_mode, w)\n",
        "    base = (alpha / r) * coeff_flow_worst\n",
        "    k_ref = base ** (1.0 / (1.0 - alpha))\n",
        "\n",
        "    # conservative cap via data-driven Rev cap\n",
        "    Rev_cap = float(np.exp(logRev_cap))\n",
        "    # Use A_ref for rough cap: Rev ≈ A_ref * k^alpha <= Rev_cap\n",
        "    k_cap = (Rev_cap / max(A_ref, 1e-12)) ** (1.0 / alpha)\n",
        "    #print(f\"kcap = {k_cap}, multiplier = {k_ref_multiplier * k_ref}\")\n",
        "    #k_max = float(min(k_ref_multiplier * k_ref, k_cap))\n",
        "    k_max = k_cap\n",
        "    print(f\"k_max = {k_max}\")\n",
        "    k_grid = np.geomspace(k_min, k_max, N_k)  # dense near zero\n",
        "\n",
        "    # omega bounds via log link\n",
        "    # Best-info reference (use Rev from flow coeff at k_ref)\n",
        "    Rev_ref = min(Rev_cap, coeff_flow_worst * (k_ref ** alpha))\n",
        "    #omega_min, den_ref, den_ref_f = omega_next_from_rev(Rev_ref, phi, tau, chi, Rev_M)\n",
        "\n",
        "    #omega_min = 0.0001 # Override omega_min\n",
        "\n",
        "    # Worst-info reference (small revenue fraction)\n",
        "    ratio_worst = 0.05\n",
        "    Rev_worst   = ratio_worst * Rev_M\n",
        "    #omega_max, den_worst, den_worst_f = omega_next_from_rev(Rev_worst, phi, tau, chi, Rev_M)\n",
        "\n",
        "    #omega_max = 0.05 # Override omega_max\n",
        "\n",
        "    omega_grid = np.geomspace(omega_min, omega_max, N_w)\n",
        "\n",
        "    print(f\"[Grids] A_ref(q={a_ref_q:.2f})={A_ref:.3g} | k_max={k_max:.3g}\")\n",
        "    print(f\"[Grids] Rev_ref={Rev_ref:.3g} | omega_min={omega_min:.3e}\")\n",
        "    print(f\"[Grids] worst Rev={Rev_worst:.3g} | omega_max={omega_max:.3e}\")\n",
        "\n",
        "    return a_grid, omega_grid, k_grid\n",
        "\n",
        "\n",
        "# ==========================\n",
        "# VFI (per a-node), vectorized\n",
        "# ==========================\n",
        "def solve_vfi_for_a(a, omega_grid, k_grid, alpha, r, phi, tau, chi, Rev_M,\n",
        "                    gamma, prod_mode, w, diag: DiagLite):\n",
        "    \"\"\"\n",
        "    Solves V(omega; a) and policy k*(omega; a) on grids via value function iteration.\n",
        "    Transition uses expected-flow productivity (omega) for Rev in the mapping.\n",
        "    \"\"\"\n",
        "    Nw, Nk = len(omega_grid), len(k_grid)\n",
        "    V = np.zeros(Nw)\n",
        "    policy_idx = np.zeros(Nw, dtype=int)\n",
        "\n",
        "    for it in range(VFI_MAXIT):\n",
        "        # Flow payoff for all states and k\n",
        "        coeff_flow = productivity_term(a, omega_grid[:, None], gamma, prod_mode, w)  # (Nw,1)\n",
        "        flow = coeff_flow * (k_grid[None, :] ** alpha) - r * k_grid[None, :]\n",
        "\n",
        "        # Count how often flow coeff was floored (diagnostic prints only if >0 overall)\n",
        "        if prod_mode == \"additive\":\n",
        "            raw_flow = a - gamma * omega_grid[:, None] - w\n",
        "        else:\n",
        "            raw_flow = (1.0 - gamma * omega_grid[:, None]) * a - w\n",
        "        diag.flow_floor_hits += int(np.count_nonzero(raw_flow < PROD_FLOOR))\n",
        "        diag.flow_total_vfi  += raw_flow.size\n",
        "        diag.states_count += Nw\n",
        "\n",
        "        # Omega' from Rev using flow coeff (deterministic transition for VFI)\n",
        "        Rev_flow = coeff_flow * (k_grid[None, :] ** alpha)  # (Nw,Nk)\n",
        "        ratio = np.maximum(Rev_flow / Rev_M, RATIO_EPS)\n",
        "        den_raw = phi + tau + chi * np.log(ratio)           # (Nw,Nk)\n",
        "        den_f = np.maximum(den_raw, DEN_FLOOR)\n",
        "        diag.den_floor_hits_vfi += int(np.count_nonzero(den_raw < DEN_FLOOR - 1e-12))\n",
        "        diag.den_total_vfi      += den_raw.size\n",
        "        omega_next = 1.0 / den_f\n",
        "\n",
        "        # Interpolate V at omega_next (linear)\n",
        "        idx = np.clip(np.searchsorted(omega_grid, omega_next, side='left') - 1, 0, Nw - 2)\n",
        "        w_hi = omega_grid[idx + 1]\n",
        "        w_lo = omega_grid[idx]\n",
        "        weight = np.divide(omega_next - w_lo, w_hi - w_lo, out=np.zeros_like(omega_next), where=(w_hi > w_lo))\n",
        "        V_next = (1.0 - weight) * V[idx] + weight * V[idx + 1]\n",
        "\n",
        "        RHS = flow + BETA * V_next\n",
        "        new_idx = np.argmax(RHS, axis=1)\n",
        "        V_new = RHS[np.arange(Nw), new_idx]\n",
        "\n",
        "        # policy boundary hits\n",
        "        diag.k_at_min_states += int(np.count_nonzero(new_idx == 0))\n",
        "        diag.k_at_max_states += int(np.count_nonzero(new_idx == Nk - 1))\n",
        "\n",
        "        # NaN/Inf guard\n",
        "        if not np.isfinite(V_new).all():\n",
        "            diag.nans_vfi += 1\n",
        "            V_new = np.where(np.isfinite(V_new), V_new, V)\n",
        "\n",
        "        diff = np.max(np.abs(V_new - V))\n",
        "        V = V_new\n",
        "        policy_idx = new_idx\n",
        "\n",
        "        if diff < VFI_TOL:\n",
        "            break\n",
        "\n",
        "    return V, policy_idx\n",
        "\n",
        "\n",
        "def solve_policy(a_grid, omega_grid, k_grid, alpha, r, phi, tau, chi, Rev_M, gamma, prod_mode, w):\n",
        "    diag = DiagLite()\n",
        "    policies = []\n",
        "    values = []\n",
        "    for a in a_grid:\n",
        "        V_a, pol_idx_a = solve_vfi_for_a(\n",
        "            a, omega_grid, k_grid, alpha, r, phi, tau, chi, Rev_M,\n",
        "            gamma, prod_mode, w, diag\n",
        "        )\n",
        "        policies.append(pol_idx_a)\n",
        "        values.append(V_a)\n",
        "    policies = np.stack(policies, axis=0)  # (Na, Nw)\n",
        "    values = np.stack(values, axis=0)      # (Na, Nw)\n",
        "\n",
        "    # Only print if something actually hit\n",
        "    diag.report(label=\"VFI\")\n",
        "    return values, policies, diag\n",
        "\n",
        "\n",
        "# ==========================\n",
        "# Simulation -> DataFrame\n",
        "# ==========================\n",
        "def simulate_panel(N_firms, T, a_grid, omega_grid, k_grid, policies,\n",
        "                   mu_lnA, sd_lnA, alpha, phi, tau, chi, Rev_M,\n",
        "                   gamma, prod_mode, w, seed=2025):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    # draw permanent A_i ~ LogNormal\n",
        "    lnA = rng.normal(mu_lnA, sd_lnA, size=N_firms)\n",
        "    A = np.exp(lnA)\n",
        "\n",
        "    # init states (start from median omega)\n",
        "    omega0 = float(np.median(omega_grid))\n",
        "    omega = np.full(N_firms, omega0)\n",
        "\n",
        "    # nearest-neighbor indexers\n",
        "    def idx_a(a_i):\n",
        "        return int(np.clip(np.searchsorted(a_grid, a_i, side='left'), 1, len(a_grid)-1) - 1)\n",
        "    def idx_w(w_i):\n",
        "        return int(np.clip(np.searchsorted(omega_grid, w_i, side='left'), 1, len(omega_grid)-1) - 1)\n",
        "\n",
        "    rows = []\n",
        "    diag = DiagLite()\n",
        "\n",
        "    for t in range(T):\n",
        "        for i in range(N_firms):\n",
        "            a_i = A[i]\n",
        "            iw  = idx_w(omega[i])\n",
        "            ia  = idx_a(a_i)\n",
        "            k   = k_grid[policies[ia, iw]]\n",
        "\n",
        "            # realized productivity with psi^2\n",
        "            z   = rng.standard_normal()\n",
        "            psi2 = omega[i] * (z ** 2)\n",
        "            coeff_real = productivity_term(a_i, psi2, gamma, prod_mode, w)\n",
        "            if coeff_real <= PROD_FLOOR + 1e-14:\n",
        "                diag.real_floor_hits += 1\n",
        "            diag.real_total_sim += 1\n",
        "\n",
        "            Rev  = coeff_real * (k ** alpha)\n",
        "            FE   = psi2\n",
        "\n",
        "            # omega update with log link (den floored at 2)\n",
        "            ratio = max(Rev / Rev_M, RATIO_EPS)\n",
        "            den_raw = phi + tau + chi * np.log(ratio)\n",
        "            if den_raw < DEN_FLOOR - 1e-12:\n",
        "                diag.den_floor_hits_sim += 1\n",
        "            den = max(den_raw, DEN_FLOOR)\n",
        "            omega_new = 1.0 / den\n",
        "\n",
        "            # bound hits (relative to grid)\n",
        "            diag.omega_updates_sim += 1\n",
        "            if omega_new <= omega_grid[0] * (1 + 1e-12):\n",
        "                diag.omega_at_min_sim += 1\n",
        "            if omega_new >= omega_grid[-1] * (1 - 1e-12):\n",
        "                diag.omega_at_max_sim += 1\n",
        "\n",
        "            if not (np.isfinite(Rev) and np.isfinite(omega_new)):\n",
        "                diag.nans_sim += 1\n",
        "\n",
        "            # record row\n",
        "            rows.append({\n",
        "                \"firm\": i,\n",
        "                \"time\": t,\n",
        "                \"Rev\":  float(Rev),\n",
        "                \"FE\":   float(FE),\n",
        "                \"K\":    float(k),\n",
        "                \"Omega\":float(omega[i]),\n",
        "                \"A\":    float(a_i),\n",
        "                \"lnA\":  float(np.log(max(a_i, 1e-300))),\n",
        "            })\n",
        "\n",
        "            # advance state\n",
        "            omega[i] = omega_new\n",
        "\n",
        "    # Print only if something was hit / useful\n",
        "    diag.report(label=\"SIM\")\n",
        "\n",
        "    # Build tidy panel DataFrame\n",
        "    df = pd.DataFrame(rows).sort_values([\"firm\",\"time\"]).reset_index(drop=True)\n",
        "    return df, diag"
      ],
      "metadata": {
        "id": "oLSKFvGVpu21"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation functions"
      ],
      "metadata": {
        "id": "iJQT80Xnp9uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# Moments & regressions (DataFrame)\n",
        "# ==========================\n",
        "\n",
        "def median_k_alpha(a_grid, omega_grid, k_grid, policies, mu_lnA, alpha):\n",
        "    A_med = np.exp(mu_lnA)\n",
        "    ia = int(np.argmin(np.abs(a_grid - A_med)))\n",
        "    omega_med = float(np.median(omega_grid))\n",
        "    iw = int(np.argmin(np.abs(omega_grid - omega_med)))\n",
        "    k_M = k_grid[policies[ia, iw]]\n",
        "    return k_M ** alpha\n",
        "\n",
        "def winsorize_series(s, p=0.01):\n",
        "    \"\"\"\n",
        "    Winsorize a pandas Series at both tails by p.\n",
        "    Caps values below p-quantile and above (1-p)-quantile.\n",
        "    \"\"\"\n",
        "    lo, hi = s.quantile([p, 1 - p])\n",
        "    return s.clip(lower=lo, upper=hi)\n",
        "\n",
        "\n",
        "def compute_key_moments_df(df, w, rev_floor=1e-12, fe_floor=1e-12, winsor_p=0.00):\n",
        "    \"\"\"\n",
        "    Regression 1a (raw):      logRev_t ~ FE + lnA\n",
        "    Regression 1b (raw):      logRev_t ~ log(FE) + lnA\n",
        "    Regression 2a (raw):      FE       ~ logRev_{t-1}\n",
        "    Regression 2b (raw):      log(FE)  ~ logRev_{t-1}\n",
        "\n",
        "    Regression 1a (winsor):   logRev_t ~ FE_w + lnA\n",
        "    Regression 1b (winsor):   logRev_t ~ log(FE_w) + lnA\n",
        "    Regression 2a (winsor):   FE_w     ~ logRev_{t-1}\n",
        "    Regression 2b (winsor):   log(FE_w)~ logRev_{t-1}\n",
        "\n",
        "    Returns a dict m containing:\n",
        "      - main keys (without suffix):     winsorized regression moments\n",
        "      - *_raw keys:                     raw regression moments\n",
        "      - fitted models for both:         _res* and _res*_raw\n",
        "    \"\"\"\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # --- Construct logRev and lag ---\n",
        "    df[\"logRev\"] = np.log(np.clip(df[\"Rev\"].values, rev_floor, None))\n",
        "    df[\"logRev_lag\"] = df.groupby(\"firm\")[\"logRev\"].shift(1)\n",
        "\n",
        "    # --- FE: raw and winsorized ---\n",
        "    df[\"FE_raw\"] = df[\"FE\"]\n",
        "    df[\"FE_w\"]   = winsorize_series(df[\"FE\"], p=winsor_p)\n",
        "\n",
        "    # logFE for both versions\n",
        "    df[\"logFE_raw\"] = np.log(np.clip(df[\"FE_raw\"].values, fe_floor, None))\n",
        "    df[\"logFE_w\"]   = np.log(np.clip(df[\"FE_w\"].values,   fe_floor, None))\n",
        "\n",
        "    # --- w * k_M^alpha / Rev_M moment (unchanged) ---\n",
        "    kM_alpha = median_k_alpha(a_grid, omega_grid, k_grid, policies, MU_LNA, ALPHA)\n",
        "    moment_w_ratio = (w * kM_alpha) / REV_M\n",
        "    print(f\"[Moment] w*kM^alpha/Rev_M = {moment_w_ratio:.6g} (target 0.0016)\")\n",
        "\n",
        "    # ============= RAW REGRESSIONS =============\n",
        "\n",
        "    # 1a_raw: logRev ~ FE_raw + lnA\n",
        "    df1_raw = df.dropna(subset=[\"logRev\", \"FE_raw\", \"lnA\"])\n",
        "    X1_raw  = sm.add_constant(df1_raw[[\"FE_raw\", \"lnA\"]].values)\n",
        "    y1_raw  = df1_raw[\"logRev\"].values\n",
        "    res1_raw = sm.OLS(y1_raw, X1_raw, missing='drop').fit()\n",
        "\n",
        "    # 1b_raw: logRev ~ logFE_raw + lnA\n",
        "    df1b_raw = df.dropna(subset=[\"logRev\", \"logFE_raw\", \"lnA\"])\n",
        "    X1b_raw  = sm.add_constant(df1b_raw[[\"logFE_raw\", \"lnA\"]].values)\n",
        "    y1b_raw  = df1b_raw[\"logRev\"].values\n",
        "    res1_log_raw = sm.OLS(y1b_raw, X1b_raw, missing='drop').fit()\n",
        "\n",
        "    # 2a_raw: FE_raw ~ logRev_lag\n",
        "    df2_raw = df.dropna(subset=[\"FE_raw\", \"logRev_lag\"])\n",
        "    X2_raw  = sm.add_constant(df2_raw[[\"logRev_lag\"]].values)\n",
        "    y2_raw  = df2_raw[\"FE_raw\"].values\n",
        "    res2_raw = sm.OLS(y2_raw, X2_raw, missing='drop').fit()\n",
        "\n",
        "    # 2b_raw: logFE_raw ~ logRev_lag\n",
        "    df2b_raw = df.dropna(subset=[\"logFE_raw\", \"logRev_lag\"])\n",
        "    X2b_raw  = sm.add_constant(df2b_raw[[\"logRev_lag\"]].values)\n",
        "    y2b_raw  = df2b_raw[\"logFE_raw\"].values\n",
        "    res2_log_raw = sm.OLS(y2b_raw, X2b_raw, missing='drop').fit()\n",
        "\n",
        "    # ============= WINSORIZED REGRESSIONS =============\n",
        "\n",
        "    # 1a_w: logRev ~ FE_w + lnA\n",
        "    df1_w = df.dropna(subset=[\"logRev\", \"FE_w\", \"lnA\"])\n",
        "    X1_w  = sm.add_constant(df1_w[[\"FE_w\", \"lnA\"]].values)\n",
        "    y1_w  = df1_w[\"logRev\"].values\n",
        "    res1_w = sm.OLS(y1_w, X1_w, missing='drop').fit()\n",
        "\n",
        "    # 1b_w: logRev ~ logFE_w + lnA\n",
        "    df1b_w = df.dropna(subset=[\"logRev\", \"logFE_w\", \"lnA\"])\n",
        "    X1b_w  = sm.add_constant(df1b_w[[\"logFE_w\", \"lnA\"]].values)\n",
        "    y1b_w  = df1b_w[\"logRev\"].values\n",
        "    res1_log_w = sm.OLS(y1b_w, X1b_w, missing='drop').fit()\n",
        "\n",
        "    # 2a_w: FE_w ~ logRev_lag\n",
        "    df2_w = df.dropna(subset=[\"FE_w\", \"logRev_lag\"])\n",
        "    X2_w  = sm.add_constant(df2_w[[\"logRev_lag\"]].values)\n",
        "    y2_w  = df2_w[\"FE_w\"].values\n",
        "    res2_w = sm.OLS(y2_w, X2_w, missing='drop').fit()\n",
        "\n",
        "    # 2b_w: logFE_w ~ logRev_lag\n",
        "    df2b_w = df.dropna(subset=[\"logFE_w\", \"logRev_lag\"])\n",
        "    X2b_w  = sm.add_constant(df2b_w[[\"logRev_lag\"]].values)\n",
        "    y2b_w  = df2b_w[\"logFE_w\"].values\n",
        "    res2_log_w = sm.OLS(y2b_w, X2b_w, missing='drop').fit()\n",
        "\n",
        "    # ============= MOMENTS =============\n",
        "\n",
        "    m = dict()\n",
        "\n",
        "    # Keep FE distribution moments on RAW FE (closer to the model)\n",
        "    m[\"logRev_mean\"] = float(df[\"logRev\"].mean())\n",
        "    m[\"logRev_sd\"]   = float(df[\"logRev\"].std())\n",
        "    m[\"FE_median\"]   = float(df[\"FE_raw\"].median())\n",
        "    m[\"FE_mean\"]     = float(df[\"FE_raw\"].mean())\n",
        "    m[\"FE_sd\"]       = float(df[\"FE_raw\"].std())\n",
        "\n",
        "    # ----- RAW regression moments (store with *_raw suffix) -----\n",
        "    m[\"beta_FE_in_logRev_raw\"]        = float(res1_raw.params[1])\n",
        "    m[\"beta_lnA_in_logRev_raw\"]       = float(res1_raw.params[2])\n",
        "    m[\"R2_reg1_raw\"]                  = float(res1_raw.rsquared)\n",
        "    m[\"n_reg1_raw\"]                   = int(res1_raw.nobs)\n",
        "\n",
        "    m[\"beta_logFE_in_logRev_raw\"]     = float(res1_log_raw.params[1])\n",
        "    m[\"beta_lnA_in_logRev_log_raw\"]   = float(res1_log_raw.params[2])\n",
        "    m[\"R2_reg1_log_raw\"]              = float(res1_log_raw.rsquared)\n",
        "    m[\"n_reg1_log_raw\"]               = int(res1_log_raw.nobs)\n",
        "\n",
        "    m[\"beta_logRevLag_in_FE_raw\"]     = float(res2_raw.params[1])\n",
        "    m[\"R2_reg2_raw\"]                  = float(res2_raw.rsquared)\n",
        "    m[\"n_reg2_raw\"]                   = int(res2_raw.nobs)\n",
        "\n",
        "    m[\"beta_logRevLag_in_logFE_raw\"]  = float(res2_log_raw.params[1])\n",
        "    m[\"R2_reg2_log_raw\"]              = float(res2_log_raw.rsquared)\n",
        "    m[\"n_reg2_log_raw\"]               = int(res2_log_raw.nobs)\n",
        "\n",
        "    # ----- WINSORIZED regression moments (MAIN keys, used by loss, etc.) -----\n",
        "    m[\"beta_FE_in_logRev\"]            = float(res1_w.params[1])\n",
        "    m[\"beta_lnA_in_logRev\"]           = float(res1_w.params[2])\n",
        "    m[\"R2_reg1\"]                      = float(res1_w.rsquared)\n",
        "    m[\"n_reg1\"]                       = int(res1_w.nobs)\n",
        "\n",
        "    m[\"beta_logFE_in_logRev\"]         = float(res1_log_w.params[1])\n",
        "    m[\"beta_lnA_in_logRev_log\"]       = float(res1_log_w.params[2])\n",
        "    m[\"R2_reg1_log\"]                  = float(res1_log_w.rsquared)\n",
        "    m[\"n_reg1_log\"]                   = int(res1_log_w.nobs)\n",
        "\n",
        "    m[\"beta_logRevLag_in_FE\"]         = float(res2_w.params[1])\n",
        "    m[\"R2_reg2\"]                      = float(res2_w.rsquared)\n",
        "    m[\"n_reg2\"]                       = int(res2_w.nobs)\n",
        "\n",
        "    m[\"beta_logRevLag_in_logFE\"]      = float(res2_log_w.params[1])\n",
        "    m[\"R2_reg2_log\"]                  = float(res2_log_w.rsquared)\n",
        "    m[\"n_reg2_log\"]                   = int(res2_log_w.nobs)\n",
        "\n",
        "    # store fitted models\n",
        "    # main (winsorized) versions keep the old names\n",
        "    m[\"_res1\"]      = res1_w\n",
        "    m[\"_res1_log\"]  = res1_log_w\n",
        "    m[\"_res2\"]      = res2_w\n",
        "    m[\"_res2_log\"]  = res2_log_w\n",
        "\n",
        "    # raw versions with *_raw suffix\n",
        "    m[\"_res1_raw\"]      = res1_raw\n",
        "    m[\"_res1_log_raw\"]  = res1_log_raw\n",
        "    m[\"_res2_raw\"]      = res2_raw\n",
        "    m[\"_res2_log_raw\"]  = res2_log_raw\n",
        "\n",
        "    m[\"w_ratio_median\"] = moment_w_ratio\n",
        "\n",
        "    return m\n",
        "\n",
        "\n",
        "def print_key_moments(m):\n",
        "    print(\"=== Key moments ===\")\n",
        "    print(f\"{'logRev_mean:':>26}  {m['logRev_mean']:.4f}\")\n",
        "    print(f\"{'logRev_sd:':>26}  {m['logRev_sd']:.4f}\")\n",
        "    print(f\"{'FE_median:':>26}  {m['FE_median']:.4f}\")\n",
        "    print(f\"{'FE_mean:':>26}  {m['FE_mean']:.4f}\")\n",
        "    print(f\"{'FE_sd:':>26}  {m['FE_sd']:.4f}\")\n",
        "    print(f\"{'beta_FE_in_logRev:':>26}  {m['beta_FE_in_logRev']:.4f}\")\n",
        "    print(f\"{'beta_lnA_in_logRev:':>26}  {m['beta_lnA_in_logRev']:.4f}\")\n",
        "    print(f\"{'R2_reg1:':>26}  {m['R2_reg1']:.4f}\")\n",
        "    print(f\"{'beta_logFE_in_logRev:':>26}  {m['beta_logFE_in_logRev']:.4f}\")\n",
        "    print(f\"{'R2_reg1_log:':>26}  {m['R2_reg1_log']:.4f}\")\n",
        "    print(f\"{'n_reg1_log:':>26}  {m['n_reg1_log']}\")\n",
        "    print(f\"{'beta_logRevLag_in_FE:':>26}  {m['beta_logRevLag_in_FE']:.4f}\")\n",
        "    print(f\"{'R2_reg2:':>26}  {m['R2_reg2']:.4f}\")\n",
        "    print(f\"{'n_reg2:':>26}  {m['n_reg2']}\")\n",
        "    # NEW: log(FE) ~ logRev_lag\n",
        "    print(f\"{'beta_logRevLag_in_logFE:':>26}  {m['beta_logRevLag_in_logFE']:.4f}\")\n",
        "    print(f\"{'R2_reg2_log:':>26}  {m['R2_reg2_log']:.4f}\")\n",
        "    print(f\"{'n_reg2_log:':>26}  {m['n_reg2_log']}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "def print_reg_summaries(m):\n",
        "    res1     = m[\"_res1\"]\n",
        "    res1_log = m[\"_res1_log\"]\n",
        "    res2     = m[\"_res2\"]\n",
        "    res2_log = m[\"_res2_log\"]\n",
        "\n",
        "    # Label regressors\n",
        "    res1.model.data.xnames     = [\"const\", \"FE\", \"lnA\"]\n",
        "    res1_log.model.data.xnames = [\"const\", \"logFE\", \"lnA\"]\n",
        "    res2.model.data.xnames     = [\"const\", \"logRev_lag\"]\n",
        "    res2_log.model.data.xnames = [\"const\", \"logRev_lag\"]\n",
        "\n",
        "    print(\"=== Regression 1a: logRev ~ FE + lnA ===\")\n",
        "    print(res1.summary().tables[1].as_text()); print()\n",
        "\n",
        "    print(\"=== Regression 1b: logRev ~ log(FE) + lnA ===\")\n",
        "    print(res1_log.summary().tables[1].as_text()); print()\n",
        "\n",
        "    print(\"=== Regression 2a: FE ~ logRev_lag ===\")\n",
        "    print(res2.summary().tables[1].as_text()); print()\n",
        "\n",
        "    print(\"=== Regression 2b: log(FE) ~ logRev_lag ===\")\n",
        "    print(res2_log.summary().tables[1].as_text()); print()\n",
        "\n",
        "\n",
        "def evaluate_targets_and_loss(m, targets):\n",
        "    \"\"\"\n",
        "    targets = {\n",
        "      'logRev_mean': 6.63,\n",
        "      'logRev_sd': 1.72,\n",
        "      'beta_FE_in_logRev': -0.87,\n",
        "      'beta_logRevLag_in_FE': -0.0055\n",
        "    }\n",
        "    \"\"\"\n",
        "    rows = [\n",
        "        (\"Mean log revenue\",          \"logRev_mean\"),\n",
        "        (\"SD log revenue\",            \"logRev_sd\"),\n",
        "        (\"β_logFE in logRev (reg1)\",     \"beta_logFE_in_logRev\"),\n",
        "        (\"β_logRevLag in log FE (reg2)\",  \"beta_logRevLag_in_logFE\"),\n",
        "        (\"w * k_M^alpha / Rev_M\",     \"w_ratio_median\"),  # <-- NEW ROW\n",
        "    ]\n",
        "    print(\"=== Targets vs Model (and loss terms) ===\")\n",
        "    print(f\"{'Moment':35} {'Target':>12} {'Model':>12} {'Model/Target':>14} {'|ratio-1|':>14}\")\n",
        "    loss_terms = []\n",
        "    for label, key in rows:\n",
        "        tgt = float(targets[key])\n",
        "        mdl = float(m[key])\n",
        "        ratio = mdl / tgt\n",
        "        term = abs(ratio - 1.0)\n",
        "        loss_terms.append(term)\n",
        "        print(f\"{label:35} {tgt:12.6f} {mdl:12.6f} {ratio:14.6f} {term:14.6f}\")\n",
        "    total_loss = float(np.sum(loss_terms))\n",
        "    print(f\"{'Total loss':35} {'':12} {'':12} {'':14} {total_loss:14.6f}\\n\")\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "leFW9VMXmJeO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ],
      "metadata": {
        "id": "MfnJACsjqM3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Main"
      ],
      "metadata": {
        "id": "bFA0BtBJqCqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =================================\n",
        "# Global constants / numeric floors\n",
        "# =================================\n",
        "BETA       = 1.0 / 1.04  # discount factor (r ~ 0.04)\n",
        "PROD_FLOOR = 0.001         # min productivity term (flow & realized)\n",
        "DEN_FLOOR  = 1.6         # min denominator in omega mapping\n",
        "RATIO_EPS  = 1e-12       # floor inside log(Rev/Rev_M)\n",
        "VFI_TOL    = 1e-6        # convergence tolerance for VFI\n",
        "VFI_MAXIT  = 500         # max VFI iterations\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # --- Parameters you can tweak ---\n",
        "    MU_LNA  = 3.77\n",
        "    SD_LNA  = 1.05\n",
        "    ALPHA   = 1/3\n",
        "    r       = 0.04\n",
        "    PHI     = 142.85\n",
        "    TAU     = 293.77\n",
        "    REV_M   = 658\n",
        "    w = 0.056\n",
        "    #PROD_MODE = \"additive\"   # or  \"multiplicative\"\n",
        "    PROD_MODE = \"multiplicative\"\n",
        "    if PROD_MODE == \"additive\":\n",
        "        GAMMA   = 1.19 # additive\n",
        "        CHI     = 117.0\n",
        "    else:\n",
        "        GAMMA   = 1.47    # multiplicative\n",
        "        CHI     = 126\n",
        "\n",
        "\n",
        "    # --- Build grids ---\n",
        "    a_grid, omega_grid, k_grid = make_grids(\n",
        "        MU_LNA, SD_LNA,\n",
        "        N_a=51, N_w=201, N_k=101,\n",
        "        alpha=ALPHA, r=r,\n",
        "        phi=PHI, tau=TAU, chi=CHI, Rev_M=REV_M,\n",
        "        gamma=GAMMA, prod_mode=PROD_MODE, w = w,\n",
        "        k_min=1, logRev_cap=9.00, a_ref_q=0.8,\n",
        "        omega_min = 1e-7, omega_max = 0.5\n",
        "    )\n",
        "\n",
        "    # --- Solve policies ---\n",
        "    values, policies, diag_vfi = solve_policy(\n",
        "        a_grid, omega_grid, k_grid,\n",
        "        alpha=ALPHA, r=r, phi=PHI, tau=TAU, chi=CHI, Rev_M=REV_M,\n",
        "        gamma=GAMMA, prod_mode=PROD_MODE, w = w\n",
        "    )\n",
        "\n",
        "    # --- Simulate panel (now returns a DataFrame) ---\n",
        "    df_panel, diag_sim = simulate_panel(\n",
        "        N_firms=1000, T=100,  # bump T for cleaner lag regression\n",
        "        a_grid=a_grid, omega_grid=omega_grid, k_grid=k_grid, policies=policies,\n",
        "        mu_lnA=MU_LNA, sd_lnA=SD_LNA, alpha=ALPHA,\n",
        "        phi=PHI, tau=TAU, chi=CHI, Rev_M=REV_M,\n",
        "        gamma=GAMMA, prod_mode=PROD_MODE, w = w,\n",
        "        seed=2025\n",
        "    )\n",
        "\n",
        "    # --- Moments, regressions, loss ---\n",
        "    moments = compute_key_moments_df(df_panel, w)\n",
        "    print_key_moments(moments)\n",
        "\n",
        "    print(\"β_logFE in logRev (RAW):       \", moments[\"beta_logFE_in_logRev_raw\"])\n",
        "    print(\"β_logFE in logRev (WINSORIZED):\", moments[\"beta_logFE_in_logRev\"])\n",
        "\n",
        "    print(\"β_logRevLag in logFE (raw vs win):\",\n",
        "          moments[\"beta_logRevLag_in_logFE_raw\"],\n",
        "          moments[\"beta_logRevLag_in_logFE\"])\n",
        "\n",
        "    print_reg_summaries(moments)\n",
        "\n",
        "    targets = {\n",
        "        \"logRev_mean\": 6.63,\n",
        "        \"logRev_sd\": 1.72,\n",
        "        \"beta_logFE_in_logRev\": -0.0163,\n",
        "        \"beta_logRevLag_in_logFE\": -0.41,\n",
        "        \"w_ratio_median\": 0.0016,  # NEW\n",
        "    }\n",
        "    _ = evaluate_targets_and_loss(moments, targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8O1REJemad1",
        "outputId": "ed723982-d046-4f1d-b407-61e9c450a78b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k_max = 491789.31892578094\n",
            "[Grids] A_ref(q=0.80)=103 | k_max=4.92e+05\n",
            "[Grids] Rev_ref=408 | omega_min=1.000e-07\n",
            "[Grids] worst Rev=32.9 | omega_max=5.000e-01\n",
            "[VFI] omega-denominator floored (VFI): 3.71% (18814794/507362592)\n",
            "[VFI] policy grid hits: k_min=0.00%, k_max=0.00% (of 5023392 states)\n",
            "[SIM] realized productivity floored: 0.06% (64/100000)\n",
            "[SIM] omega bound hits (SIM): min=0.00%, max=0.45% (of 100000 updates)\n",
            "[Moment] w*kM^alpha/Rev_M = 0.00158901 (target 0.0016)\n",
            "=== Key moments ===\n",
            "              logRev_mean:  6.6708\n",
            "                logRev_sd:  1.5945\n",
            "                FE_median:  0.0011\n",
            "                  FE_mean:  0.0060\n",
            "                    FE_sd:  0.0679\n",
            "        beta_FE_in_logRev:  -3.0916\n",
            "       beta_lnA_in_logRev:  1.4686\n",
            "                  R2_reg1:  0.9907\n",
            "     beta_logFE_in_logRev:  -0.0122\n",
            "              R2_reg1_log:  0.9740\n",
            "               n_reg1_log:  100000\n",
            "     beta_logRevLag_in_FE:  -0.0080\n",
            "                  R2_reg2:  0.0349\n",
            "                   n_reg2:  99000\n",
            "  beta_logRevLag_in_logFE:  -0.3832\n",
            "              R2_reg2_log:  0.0686\n",
            "               n_reg2_log:  99000\n",
            "\n",
            "β_logFE in logRev (RAW):        -0.012243358150969316\n",
            "β_logFE in logRev (WINSORIZED): -0.012243358150969316\n",
            "β_logRevLag in logFE (raw vs win): -0.38320774099490784 -0.38320774099490784\n",
            "=== Regression 1a: logRev ~ FE + lnA ===\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          1.1602      0.002    634.742      0.000       1.157       1.164\n",
            "FE            -3.0916      0.007   -428.513      0.000      -3.106      -3.078\n",
            "lnA            1.4686      0.000   3149.499      0.000       1.468       1.469\n",
            "==============================================================================\n",
            "\n",
            "=== Regression 1b: logRev ~ log(FE) + lnA ===\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.9724      0.004    274.474      0.000       0.966       0.979\n",
            "logFE         -0.0122      0.000    -34.142      0.000      -0.013      -0.012\n",
            "lnA            1.4898      0.001   1864.892      0.000       1.488       1.491\n",
            "==============================================================================\n",
            "\n",
            "=== Regression 2a: FE ~ logRev_lag ===\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.0594      0.001     64.765      0.000       0.058       0.061\n",
            "logRev_lag    -0.0080      0.000    -59.802      0.000      -0.008      -0.008\n",
            "==============================================================================\n",
            "\n",
            "=== Regression 2b: log(FE) ~ logRev_lag ===\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -4.6985      0.031   -152.678      0.000      -4.759      -4.638\n",
            "logRev_lag    -0.3832      0.004    -85.406      0.000      -0.392      -0.374\n",
            "==============================================================================\n",
            "\n",
            "=== Targets vs Model (and loss terms) ===\n",
            "Moment                                    Target        Model   Model/Target      |ratio-1|\n",
            "Mean log revenue                        6.630000     6.670767       1.006149       0.006149\n",
            "SD log revenue                          1.720000     1.594495       0.927032       0.072968\n",
            "β_logFE in logRev (reg1)               -0.016300    -0.012243       0.751126       0.248874\n",
            "β_logRevLag in log FE (reg2)           -0.410000    -0.383208       0.934653       0.065347\n",
            "w * k_M^alpha / Rev_M                   0.001600     0.001589       0.993130       0.006870\n",
            "Total loss                                                                         0.400208\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0o_DjnCr4BH",
        "outputId": "7b8b896d-29e9-4365-d56d-005138c7c9b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "# Define the path to save the file\n",
        "save_path = os.path.join(project_dir, 'Output/model_SMM5.pkl')\n",
        "\n",
        "# Create a dictionary of the variables you want to save.\n",
        "# I've included the main grids, policies, values, parameters, and results.\n",
        "saved_variables = {\n",
        "    'a_grid': a_grid,\n",
        "    'omega_grid': omega_grid,\n",
        "    'k_grid': k_grid,\n",
        "    'policies': policies,\n",
        "    'values': values,\n",
        "    'df_panel': df_panel,\n",
        "    'moments': moments,\n",
        "    'targets': targets,\n",
        "    'MU_LNA': MU_LNA,\n",
        "    'SD_LNA': SD_LNA,\n",
        "    'ALPHA': ALPHA,\n",
        "    'r': r,\n",
        "    'PHI': PHI,\n",
        "    'TAU': TAU,\n",
        "    'CHI': CHI,\n",
        "    'REV_M': REV_M,\n",
        "    'w': w,\n",
        "    'GAMMA': GAMMA,\n",
        "    'PROD_MODE': PROD_MODE,\n",
        "    'BETA': BETA,\n",
        "    'PROD_FLOOR': PROD_FLOOR,\n",
        "    'DEN_FLOOR': DEN_FLOOR,\n",
        "    'RATIO_EPS': RATIO_EPS,\n",
        "    'VFI_TOL': VFI_TOL,\n",
        "    'VFI_MAXIT': VFI_MAXIT\n",
        "}\n",
        "\n",
        "# Save the dictionary to a pickle file\n",
        "with open(save_path, 'wb') as f:\n",
        "    pickle.dump(saved_variables, f)\n",
        "\n",
        "print(f\"All selected variables saved to: {save_path}\")"
      ],
      "metadata": {
        "id": "LqCBevdumdtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb7325c-bbee-4e8b-e3e6-c60cdfa40b4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All selected variables saved to: /content/drive/MyDrive/Data_GDP_OV/Output/model_SMM5.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2meGvGUErvHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0f83112"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}